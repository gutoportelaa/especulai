# üöÄ Guia Passo a Passo: Treinamento do Modelo Gradient Boosting

Este guia explica como executar o treinamento do modelo de predi√ß√£o de pre√ßos de im√≥veis **localmente** (n√£o √© necess√°rio usar Google Colab).

## üìã Pr√©-requisitos

Antes de come√ßar, certifique-se de ter:

1. **Python 3.10+** instalado
2. **Ambiente virtual** ativado (`.venv`)
3. **Depend√™ncias** instaladas
4. **Arquivo FipeZap** na raiz do projeto (`fipezap-teresina.csv`)

## üîç Verifica√ß√£o Inicial

Verifique se os arquivos necess√°rios existem:

```bash
# Na raiz do projeto (especulai_v0.0/)
ls dados_imoveis_teresina/enriched_economic.csv  # Deve existir
ls fipezap-teresina.csv  # Deve existir
```

## üìù Passo a Passo Completo

### **Passo 1: Ativar o Ambiente Virtual**

```powershell
# No PowerShell (Windows)
cd C:\Users\gutop\Desktop\especulai_v0.0
.\.venv\Scripts\Activate.ps1
```

Ou se estiver usando Git Bash:
```bash
source .venv/Scripts/activate
```

### **Passo 2: Verificar Depend√™ncias**

```bash
pip install -r especulai/requirements.txt
```

Principais depend√™ncias necess√°rias:
- `pandas`
- `numpy`
- `scikit-learn`
- `joblib`

### **Passo 3: Executar o Pipeline de Dados (se necess√°rio)**

‚ö†Ô∏è **IMPORTANTE**: O arquivo `enriched_economic.csv` deve existir antes de treinar o modelo.

Se o arquivo n√£o existir ou estiver desatualizado, execute o pipeline completo:

```bash
cd especulai/ml/pipeline
python pipeline_ml.py
```

Este script executa:
1. **M√≥dulo 1**: Coleta de dados (scraping)
2. **M√≥dulo 2**: Enriquecimento geoespacial
3. **M√≥dulo 3**: Enriquecimento econ√¥mico (usa `fipezap-teresina.csv`)
4. **M√≥dulo 4**: Limpeza e prepara√ß√£o final

**Tempo estimado**: 5-15 minutos (dependendo do tamanho do dataset)

### **Passo 4: Verificar o Dataset**

Antes de treinar, verifique se o dataset tem a coluna `Tipo_Negocio`:

```bash
python -c "import pandas as pd; df = pd.read_csv('dados_imoveis_teresina/enriched_economic.csv'); print('Colunas:', df.columns.tolist()); print('Tipo_Negocio:', df['Tipo_Negocio'].value_counts() if 'Tipo_Negocio' in df.columns else 'N√ÉO ENCONTRADO')"
```

### **Passo 5: Treinar o Modelo**

Execute o script de treinamento:

```bash
# A partir da raiz do projeto
python especulai/ml/pipeline/train_model.py
```

Ou:

```bash
cd especulai/ml/pipeline
python train_model.py
```

**O que acontece durante o treinamento:**

1. ‚úÖ Carrega o dataset `enriched_economic.csv`
2. ‚úÖ **Separa automaticamente** os dados de **Venda** e **Aluguel**
3. ‚úÖ Salva o dataset de aluguel em `dados_imoveis_teresina/dataset_aluguel.csv`
4. ‚úÖ Filtra apenas **Venda** para treinamento
5. ‚úÖ Prepara features (√°rea, quartos, banheiros, tipo, bairro, cidade)
6. ‚úÖ Treina o modelo **Gradient Boosting** com par√¢metros validados:
   - `n_estimators=200`
   - `learning_rate=0.1`
   - `max_depth=5`
7. ‚úÖ Avalia o modelo (MAE, RMSE, R¬≤)
8. ‚úÖ Salva o modelo em `especulai/ml/artifacts/modelo_definitivo.joblib`
9. ‚úÖ Salva o pr√©-processador em `especulai/ml/artifacts/preprocessador.joblib`

**Tempo estimado**: 1-5 minutos (dependendo do tamanho do dataset)

### **Passo 6: Verificar os Resultados**

Ap√≥s o treinamento, verifique:

```bash
# Verificar se o modelo foi salvo
ls especulai/ml/artifacts/modelo_definitivo.joblib

# Verificar se o dataset de aluguel foi separado
ls dados_imoveis_teresina/dataset_aluguel.csv
```

## üìä Sa√≠da Esperada

Durante o treinamento, voc√™ ver√° algo como:

```
=== Especulai - Treinamento Gradient Boosting (Modelo Definitivo) ===
‚úì Dataset de ALUGUEL salvo: C:\Users\gutop\Desktop\especulai_v0.0\dados_imoveis_teresina\dataset_aluguel.csv (150 registros)
‚úì Filtrado para VENDA: 850 registros para treinamento

=== M√©tricas de Desempenho (Gradient Boosting) ===
MAE : R$ 23,456.78
RMSE: R$ 28,901.23
R¬≤  : 0.9963

‚úì Modelo salvo em especulai/ml/artifacts/modelo_definitivo.joblib
‚úì Pr√©-processador salvo em especulai/ml/artifacts/preprocessador.joblib

‚úì Treinamento conclu√≠do com sucesso!
```

## ‚ö†Ô∏è Solu√ß√£o de Problemas

### Erro: "Dataset n√£o encontrado"

**Problema**: O arquivo `enriched_economic.csv` n√£o existe.

**Solu√ß√£o**:
```bash
# Execute o pipeline primeiro
cd especulai/ml/pipeline
python pipeline_ml.py
```

### Erro: "Nenhum registro de VENDA encontrado"

**Problema**: O dataset n√£o tem registros com `Tipo_Negocio = 'Venda'`.

**Solu√ß√£o**: Verifique o dataset:
```bash
python -c "import pandas as pd; df = pd.read_csv('dados_imoveis_teresina/enriched_economic.csv'); print(df['Tipo_Negocio'].value_counts())"
```

### Erro: "Arquivo FipeZap n√£o encontrado"

**Problema**: O arquivo `fipezap-teresina.csv` n√£o est√° na raiz do projeto.

**Solu√ß√£o**: Certifique-se de que o arquivo est√° em:
```
especulai_v0.0/fipezap-teresina.csv
```

## üîÑ Treinamento no Google Colab (Opcional)

Se preferir usar o Google Colab para experimenta√ß√£o:

1. **Fa√ßa upload do notebook**:
   - `especulai/notebooks/analise_modelos.ipynb`

2. **Fa√ßa upload dos dados**:
   - `dados_imoveis_teresina/enriched_economic.csv`
   - `fipezap-teresina.csv`

3. **Execute o notebook** no Colab

‚ö†Ô∏è **Nota**: O treinamento local √© mais r√°pido e n√£o requer upload de dados grandes.

## üìå Resumo R√°pido

```bash
# 1. Ativar ambiente virtual
.\.venv\Scripts\Activate.ps1

# 2. Executar pipeline (se necess√°rio)
cd especulai/ml/pipeline
python pipeline_ml.py

# 3. Treinar modelo
python train_model.py

# 4. Verificar resultados
ls ../artifacts/modelo_definitivo.joblib
```

## ‚úÖ Checklist Final

- [ ] Ambiente virtual ativado
- [ ] Depend√™ncias instaladas
- [ ] Arquivo `fipezap-teresina.csv` na raiz
- [ ] Arquivo `enriched_economic.csv` existe
- [ ] Pipeline executado (se necess√°rio)
- [ ] Modelo treinado com sucesso
- [ ] Dataset de aluguel separado
- [ ] Modelo salvo em `ml/artifacts/`

---

**Pronto!** Seu modelo est√° treinado e pronto para uso na API. üéâ


