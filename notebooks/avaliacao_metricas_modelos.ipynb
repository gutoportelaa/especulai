{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliacao das metricas dos modelos\n",
        "\n",
        "Este notebook compila as principais metricas observadas durante os treinamentos recentes (RMSE, MAE, R2, MAPE e acuracias relativas) para apoiar decisoes sobre o melhor modelo a ser promovido em producao.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "sns.set_palette(\"viridis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caminho relativo ao repo\n",
        "root = Path(__file__).resolve().parents[2]\n",
        "comparacao_path = root / \"ml\" / \"artifacts\" / \"comparacao_modelos_full.csv\"\n",
        "\n",
        "if not comparacao_path.exists():\n",
        "    raise FileNotFoundError(f\"Arquivo nao encontrado: {comparacao_path}\")\n",
        "\n",
        "df_metricas = pd.read_csv(comparacao_path)\n",
        "df_metricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def melhores_por_metrica(df: pd.DataFrame, metricas_min, metricas_max):\n",
        "    registros = []\n",
        "    for metrica in metricas_min:\n",
        "        linha = df.loc[df[metrica].idxmin()]\n",
        "        registros.append({\"metrica\": metrica, \"modelo\": linha[\"modelo\"], \"valor\": linha[metrica], \"criterio\": \"menor\"})\n",
        "    for metrica in metricas_max:\n",
        "        linha = df.loc[df[metrica].idxmax()]\n",
        "        registros.append({\"metrica\": metrica, \"modelo\": linha[\"modelo\"], \"valor\": linha[metrica], \"criterio\": \"maior\"})\n",
        "    return pd.DataFrame(registros)\n",
        "\n",
        "metricas_min = [\"rmse\", \"mae\", \"mape\"]\n",
        "metricas_max = [\"r2\", \"accuracy_10pct\", \"accuracy_20pct\"]\n",
        "melhores_metricas = melhores_por_metrica(df_metricas, metricas_min, metricas_max)\n",
        "melhores_metricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rank_composto(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    normalizado = df.copy()\n",
        "    for coluna in metricas_min:\n",
        "        normalizado[coluna + \"_score\"] = 1 - (normalizado[coluna] - normalizado[coluna].min()) / (normalizado[coluna].max() - normalizado[coluna].min())\n",
        "    for coluna in metricas_max:\n",
        "        normalizado[coluna + \"_score\"] = (normalizado[coluna] - normalizado[coluna].min()) / (normalizado[coluna].max() - normalizado[coluna].min())\n",
        "    score_cols = [c for c in normalizado.columns if c.endswith(\"_score\")]\n",
        "    normalizado[\"score_composto\"] = normalizado[score_cols].mean(axis=1)\n",
        "    return normalizado.sort_values(\"score_composto\", ascending=False)[[\"modelo\", \"tipo\", \"score_composto\"] + score_cols]\n",
        "\n",
        "ranking = rank_composto(df_metricas)\n",
        "ranking.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "sns.barplot(data=df_metricas, x=\"modelo\", y=\"r2\", ax=axes[0, 0])\n",
        "axes[0, 0].set_title(\"R2 por modelo\")\n",
        "axes[0, 0].tick_params(axis=\"x\", rotation=45, ha=\"right\")\n",
        "\n",
        "sns.barplot(data=df_metricas, x=\"modelo\", y=\"mae\", ax=axes[0, 1])\n",
        "axes[0, 1].set_title(\"MAE por modelo (quanto menor melhor)\")\n",
        "axes[0, 1].tick_params(axis=\"x\", rotation=45, ha=\"right\")\n",
        "\n",
        "sns.barplot(data=df_metricas, x=\"modelo\", y=\"rmse\", ax=axes[1, 0])\n",
        "axes[1, 0].set_title(\"RMSE por modelo (quanto menor melhor)\")\n",
        "axes[1, 0].tick_params(axis=\"x\", rotation=45, ha=\"right\")\n",
        "\n",
        "sns.barplot(data=df_metricas, x=\"modelo\", y=\"accuracy_10pct\", ax=axes[1, 1])\n",
        "axes[1, 1].set_title(\"Acuracia de +-10% por modelo\")\n",
        "axes[1, 1].tick_params(axis=\"x\", rotation=45, ha=\"right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observacoes rapidas\n",
        "\n",
        "- Gradient Boosting e Random Forest lideram em R2, MAE e RMSE, sustentando a decisao atual de promover o Gradient Boosting.\n",
        "- XGBoost baseline ainda e competitivo em acuracias relativas, sugerindo monitorar futuras versoes com features espaciais.\n",
        "- Modelos lineares e redes neurais nao atingiram desempenho aceitavel; servem como referencias de controle.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
